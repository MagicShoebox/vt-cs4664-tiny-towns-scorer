{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Experiments\n","\n","Tiny Towns Scorer\\\n","CS 4664: Data-Centric Computing Capstone\n","\n","### Authors\n","Alex Owens, Daniel Schoenbach, Payton Klemens\n","\n","### Acknowledgements\n","\n","Portions of this project were adapted from tutorials and examples available\n","on the [OpenCV](https://opencv.org/).\n","\n","In particular, significant portions of code from the tutorials [Feature Detection and Description](https://docs.opencv.org/4.6.0/db/d27/tutorial_py_table_of_contents_feature2d.html)."],"metadata":{"id":"kmRUX-_hjnlg"}},{"cell_type":"markdown","source":["# **Note**\n","**Unlike the other notebooks, this notebook is not designed to be run in whole. It contains abandoned ideas, half-written snippets, and exploratory code from the lifetime of the project. Much or most of the code has not been tested in this context and may not run as-is.**"],"metadata":{"id":"4unHHH9dd8-7"}},{"cell_type":"markdown","source":["# Dependencies"],"metadata":{"id":"ltZYgLgiYmRi"}},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import cv2 as cv"],"metadata":{"id":"sgZb4tq2jj_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data"],"metadata":{"id":"FE52tm8TjFvv"}},{"cell_type":"markdown","source":["The collected data has been made available on [Zenodo](https://zenodo.org/record/7429657#.Y5d_np7MKUk).\n","\n","The dataset is over 1 GB. To avoid re-downloading it each time, the notebook saves it to Google Drive."],"metadata":{"id":"rzpcyI-40jxv"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"VxxdJ3krhGiw"},"outputs":[],"source":["# If you do not want to connect the notebook to your Google Drive,\n","# simply uncomment this line and comment the three below\n","# PROJECT_FOLDER = '/content'\n","\n","# Comment to prevent connecting to Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","PROJECT_FOLDER = '/content/drive/My Drive/tiny-towns-scorer'\n","\n","from os import path\n","IMAGES_FOLDER = path.join(PROJECT_FOLDER, 'images')\n","ANNOTATIONS_FOLDER = path.join(PROJECT_FOLDER, 'annotations')\n","MODEL_FOLDER = path.join(PROJECT_FOLDER, 'model', 'model')\n","CHECKPOINT_PATH = \"checkpoint/\" # Note: local to runtime environment"]},{"cell_type":"code","source":["!mkdir -p \"{PROJECT_FOLDER}\"\n","!test ! -d \"{IMAGES_FOLDER}\" && wget -O \"images.tar.gz\" \"https://zenodo.org/record/7429657/files/images.tar.gz?download=1\" && tar -xzvf images.tar.gz -C \"{PROJECT_FOLDER}\"\n","!test ! -d \"{MODEL_FOLDER}\" && wget -O \"model.tar.gz\" \"https://zenodo.org/record/7429657/files/model.tar.gz?download=1\" && tar -xzvf model.tar.gz -C \"{PROJECT_FOLDER}\""],"metadata":{"id":"cdeHX0BIY7wT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Image loading functions"],"metadata":{"id":"jTCPFc1xZaZZ"}},{"cell_type":"markdown","source":["These are some convience functions for loading images, used by some of the experimental code below. Note that they typically rescale images to at least 1000px on each side (preserving aspect ratio), which the final model does not do."],"metadata":{"id":"_9rQKuDNZeOJ"}},{"cell_type":"code","source":["from os import path\n","from glob import glob\n","\n","IMAGES_FRONTAL = 'frontal'\n","IMAGES_SIDE = 'side_angle'\n","IMAGES_TOP_DOWN = 'top_down'\n","\n","IMAGES_BRICK = 'brick'\n","IMAGES_CHAPEL = 'chapel'\n","IMAGES_COTTAGE = 'cottage'\n","IMAGES_FACTORY = 'factory'\n","IMAGES_FARM = 'farm'\n","IMAGES_GLASS = 'glass'\n","IMAGES_STONE = 'stone'\n","IMAGES_TAVERN = 'tavern'\n","IMAGES_THEATER = 'theater'\n","IMAGES_WELL = 'well'\n","IMAGES_WHEAT = 'wheat'\n","IMAGES_WOOD = 'wood'\n","\n","def list_board_imgs():\n","  def board(x):\n","    return path.join(IMAGES_FOLDER, 'boards', x)\n","  return {\n","    'full': board('board_scan_full.png'),\n","    'transparent': board('board_scan_transparent.png'),\n","    'grid_outline': board('board_scan_grid_outline.png'),\n","    'grid_blocks': board('board_scan_grid_blocks.png'),\n","    'frontal': board('board_frontal.png'),\n","    'top_down': board('board_top_down.png'),\n","    'side_1': board('board_side_1.png'),\n","    'side_2': board('board_side_2.png')\n","  }\n","\n","def list_game_imgs():\n","  return {\n","    angle:\n","    [ img\n","      for ext in ['*.JPG', '*.jpeg']\n","      for img in glob(path.join(IMAGES_FOLDER, angle, ext)) ]\n","    for angle in [IMAGES_FRONTAL, IMAGES_SIDE, IMAGES_TOP_DOWN]\n","  }\n","\n","def list_piece_imgs():\n","  return {\n","    piece: glob(path.join(IMAGES_FOLDER, 'pieces', piece, '*.JPG'))\n","    for piece in [\n","      IMAGES_BRICK,\n","      IMAGES_CHAPEL,\n","      IMAGES_COTTAGE,\n","      IMAGES_FACTORY,\n","      IMAGES_FARM,\n","      IMAGES_GLASS,\n","      IMAGES_STONE,\n","      IMAGES_TAVERN,\n","      IMAGES_THEATER,\n","      IMAGES_WELL,\n","      IMAGES_WHEAT,\n","      IMAGES_WOOD\n","      ]\n","  }\n","\n","def rescale(img, max_dim):\n","  if img.shape[1] > img.shape[0]:\n","    width,height = max_dim, int(max_dim * img.shape[0]/img.shape[1])\n","  else:\n","    width,height = int(max_dim * img.shape[1]/img.shape[0]), max_dim\n","  return cv.resize(img, (width, height))\n","\n","def load_img(name):\n","  img_path = path.join(PROJECT_FOLDER, 'Images', name)\n","  return rescale(cv.cvtColor(cv.imread(img_path,cv.IMREAD_UNCHANGED),cv.COLOR_BGR2RGB), 1000)\n","\n","def load_img_gry(name):\n","  img_path = path.join(PROJECT_FOLDER, 'Images', name)\n","  return rescale(cv.imread(img_path,cv.IMREAD_GRAYSCALE), 1000)\n"],"metadata":{"id":"HncpY6zrZdFo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Manual Corner Detection"],"metadata":{"id":"1fAX8FSVt382"}},{"cell_type":"markdown","source":["Import the packages used for manual corner detection."],"metadata":{"id":"iHFoM8PozPDR"}},{"cell_type":"code","source":["from skimage.io import imread, imshow\n","from skimage import transform"],"metadata":{"id":"CoO7qstyrkLT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load an image and find the corner points manually and perform a projective transformation using skimage and display it."],"metadata":{"id":"aaapVV0ft-Et"}},{"cell_type":"code","source":["side_images = list_game_imgs()\n","tt = imread('/content/drive/Shareddrives/DCC Capstone/Images/side_angle/IMG_0237.jpeg')\n","fig, ax = plt.subplots()\n","ax.imshow(tt)\n","_ = ax.set_title('original picture')"],"metadata":{"id":"8FnewvD7rmBU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# source coords\n","src = np.array([2166, 705, \n","                945, 1251,\n","                1937, 2325,\n","                3305, 1334,]).reshape((4, 2))\n","\n","# dest coords\n","dst = np.array([1000, 1000,\n","                1000, 2500,\n","                2500, 2500,\n","                2500, 1000,]).reshape((4, 2))\n","\n","# use skimage's transform module where 'projective' is desired param\n","tform = transform.estimate_transform('projective', src, dst)\n","tf_img = transform.warp(tt, tform.inverse)\n","\n","# plotting the image\n","fig, ax = plt.subplots()\n","ax.imshow(tf_img)\n","_ = ax.set_title('projective transformation')"],"metadata":{"id":"bwqii3gxroXI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Chose not to move forward with manual since it seems unoptimal"],"metadata":{"id":"WylnV19V01V9"}},{"cell_type":"markdown","source":["# Harris Corner Detection\n"],"metadata":{"id":"MCSlM0dWuLMz"}},{"cell_type":"markdown","source":["Load an image and attempt to find corners through OpenCV's Harris Corner detection module."],"metadata":{"id":"SU4wl3tvvLhj"}},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow\n","\n","tt = cv.imread('/content/drive/Shareddrives/DCC Capstone/Images/top_down/IMG_4519.JPG')\n","gray = cv.cvtColor(tt, cv.COLOR_BGR2GRAY)\n","gray = np.float32(gray)\n","\n","# use opencv's harris corner module\n","harris_corners = cv.cornerHarris(gray, 3, 3, 0.05)\n","kernel = np.ones((7, 7), np.uint8)\n","harris_corners = cv.dilate(harris_corners, kernel, iterations=2)\n","\n","tt[harris_corners > 0.025 * harris_corners.max()] = [255, 127, 127]\n","\n","# display the resulting corner points detected\n","cv2_imshow(tt)"],"metadata":{"id":"yu2uoCeqvIIn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The results end up being poor, and don't seem to be consistent."],"metadata":{"id":"QJPVhMMt0_UN"}},{"cell_type":"markdown","source":["# Board Matching (ORB)"],"metadata":{"id":"y5ERH5XkvRL_"}},{"cell_type":"code","source":["# https://docs.opencv.org/4.6.0/d1/d89/tutorial_py_orb.html\n","\n","board_ref_img = load_img(list_board_imgs()['transparent'])\n","board_angles = ['transparent', 'top_down', 'frontal', 'side_1', 'side_2', 'grid_outline', 'grid_blocks']\n","board_imgs = [rescale(load_img(list_board_imgs()[angle]),size) for angle in board_angles for size in [1000]]\n","\n","orb = cv.ORB_create()\n","orb.setMaxFeatures(1000)\n","# orb.setNLevels(16)\n","# orb.setEdgeThreshold(47)\n","# orb.setPatchSize(47)\n","# orb.setFirstLevel(3)\n","board_ref_kp, board_ref_des = orb.detectAndCompute(board_ref_img,None)\n","board_kps, board_deses = zip(*(orb.detectAndCompute(img,None) for img in board_imgs))\n","board_Ms = []\n","for i in range(len(board_imgs)):\n","  bf = cv.BFMatcher(normType=cv.NORM_HAMMING)\n","  matches = bf.knnMatch(board_ref_des,board_deses[i],k=2)\n","  good = [m for m,n in matches if m.distance < 0.7*n.distance]\n","  src_pts = np.float32([board_ref_kp[m.queryIdx].pt for m in good]).reshape(-1,1,2)\n","  dst_pts = np.float32([board_kps[i][m.trainIdx].pt for m in good]).reshape(-1,1,2)\n","  M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n","  board_Ms.append(np.linalg.inv(M))\n","fig,ax = plt.subplots(2,len(board_imgs),figsize=(30,8))\n","if len(board_imgs) > 1:\n","  for x in range(len(board_imgs)):\n","    ax[x // len(board_imgs)][x % len(board_imgs)].imshow(cv.drawKeypoints(board_imgs[x], board_kps[x], None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DEFAULT | cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n","  for x in range(len(board_imgs),2*len(board_imgs)):\n","    ax[x // len(board_imgs)][x % len(board_imgs)].imshow(cv.warpPerspective(board_imgs[x % 7], board_Ms[x % 7], board_ref_img.shape[:2]))\n","else:\n","    ax[0].imshow(cv.drawKeypoints(board_imgs[0], board_kps[0], None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DEFAULT | cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS))\n","    ax[1].imshow(cv.warpPerspective(board_imgs[0], board_Ms[0], board_ref_img.shape[:2]))\n","plt.show()"],"metadata":{"id":"Q0LqTb95xkTN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# https://docs.opencv.org/4.6.0/d1/de0/tutorial_py_feature_homography.html\n","\n","def find_board(board_deses, scene_img, verbose=False):\n","  MIN_MATCH_COUNT = 10\n","\n","  scene_kp, scene_des = orb.detectAndCompute(scene_img,None)\n","  if verbose:\n","    fig, ax = plt.subplots(1,2,figsize=(10,10))\n","    ax[0].imshow(scene_img)\n","    ax[1].imshow(cv.drawKeypoints(scene_img, scene_kp, None, color=(0,255,0), flags=cv.DRAW_MATCHES_FLAGS_DEFAULT))\n","    plt.show()\n","\n","  bf = cv.BFMatcher(normType=cv.NORM_HAMMING)\n","\n","  match = None\n","  for i,board_des in enumerate(board_deses):\n","    matches = bf.knnMatch(board_des,scene_des,k=2)\n","    good = [m for m,n in matches if m.distance < 0.7*n.distance]\n","    if match is None or len(good) > len(match[1]):\n","      match = (i,good)\n","\n","  if len(match[1]) >= MIN_MATCH_COUNT:\n","    if verbose:\n","      print(f'Found {len(match[1])} matches')\n","    return match[0], scene_kp, match[1]\n","  else:\n","    if verbose:\n","      print(f'Not enough matches were found - {len(match[1])}/{MIN_MATCH_COUNT}')\n","    return None"],"metadata":{"id":"mz5Lg8qQxlhL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["game_imgs = list_game_imgs()\n","{\n","    angle: sum(1 for img in game_imgs[angle]\n","                if find_board(board_deses, load_img(img), False))\n","            / len(game_imgs[angle])\n","    for angle in game_imgs\n","}"],"metadata":{"id":"l5hNcln2xm6C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","# img_dir, img_file = path.split(random.choice([img for angle in [IMAGES_FRONTAL, IMAGES_SIDE, IMAGES_TOP_DOWN] for img in game_imgs[angle]]))\n","img_dir, img_file = 'side_angle', 'IMG_4517.JPG'\n","print(path.join(path.basename(img_dir), img_file))\n","scene_img = load_img(path.join(img_dir, img_file))\n","# scene_img = load_img('top_down/IMG_0267.jpeg')\n","match = find_board(board_deses, scene_img, True)\n","if match is None:\n","  raise ValueError('No match')\n","board_idx, scene_kp, good = match\n","\n","src_pts = np.float32([board_kps[board_idx][m.queryIdx].pt for m in good]).reshape(-1,1,2)\n","dst_pts = np.float32([scene_kp[m.trainIdx].pt for m in good]).reshape(-1,1,2)\n","\n","M, mask = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n","\n","if M is not None:\n","  h,w = board_imgs[board_idx].shape[:2]\n","  pts = np.float32([ [0,0], [0,h-1], [w-1,h-1], [w-1,0] ]).reshape(-1,1,2)\n","  dst = cv.perspectiveTransform(pts, M)\n","  outline_img = cv.polylines(scene_img.copy(),[np.int32(dst)],True,(255,255,255),3,cv.LINE_AA)\n","  match_img = cv.warpPerspective(scene_img, np.matmul(board_Ms[board_idx], np.linalg.inv(M)), board_ref_img.shape[:2])\n","  fig, ax = plt.subplots(1,2,figsize=(10,5))\n","  ax[0].imshow(outline_img)\n","  ax[1].imshow(match_img)\n","  plt.show()\n","\n","draw_params = {# 'matchColor': (0,255,0),\n","              'singlePointColor': None,\n","              # 'matchesMask': mask.ravel().tolist(),\n","              'flags': cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS | cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS}\n","fig,ax = plt.subplots(figsize=(15,15))\n","plt.imshow(cv.drawMatches(board_imgs[board_idx],board_kps[board_idx],outline_img if M is not None else scene_img,scene_kp,good,None,**draw_params))\n","plt.show()"],"metadata":{"id":"rugP3PNU1UNj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Split Board"],"metadata":{"id":"H-x0vFB31jJn"}},{"cell_type":"code","source":["def split_board(img, verbose=False):\n","  img_h,img_w=img.shape[:2]\n","  splits = [[None]*4]*4\n","  if verbose:\n","    fig,ax = plt.subplots(4,4,figsize=(10,10))\n","  for x in range(4):\n","    for y in range(4):\n","      x0 = int(x*img_h/4.45)\n","      x1 = int((x+1.33)*(img_h)/4.25)\n","      y0 = int(y*img_h/4.45)\n","      y1 = int((y+1.33)*(img_h/4.25))\n","      splits[x][y] = img[max(y0,0):min(y1,img_h),max(x0,0):min(x1,img_w)]\n","      if verbose:\n","        ax[y][x].imshow(splits[x][y])\n","  return splits"],"metadata":{"id":"JuXe-XpB1k2a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Individual Pieces Pipeline"],"metadata":{"id":"tPdjDpCYa-Rh"}},{"cell_type":"markdown","source":["This function could be used with the pipelines developed in `training.ipynb` to create a pipeline of individual piece images. The idea was to train a CNN to classify individual pieces, then feed it the extracted portions of a detected grid. This approach was abandoned in favor of an object detection network that classifies pieces and positions at the same time."],"metadata":{"id":"lFvzcUH4bDx8"}},{"cell_type":"code","source":["# Converts whole images into a list of all the individual objects\n","# As above, intended for use with dataset.apply()\n","# Haven't tested recently, but could be used to train traditional CNN\n","def to_pieces(bounding_box_format='xywh'):\n","\n","  def get_pieces(record):\n","    image = record['images']\n","    def get_piece(box):\n","      print(box)\n","      xmin = tf.cast(tf.math.rint(box[0]), tf.int64)\n","      ymin = tf.cast(tf.math.rint(box[1]), tf.int64)\n","      xmax = tf.cast(tf.math.rint(box[0]+box[2]), tf.int64)\n","      ymax = tf.cast(tf.math.rint(box[1]+box[3]), tf.int64)\n","      return {\n","          'image': image[ymin:ymax,xmin:xmax],\n","          'label': tf.cast(box[4], tf.int64)\n","      }\n","    boxes_in_xywh=keras_cv.bounding_box.convert_format(record['bounding_boxes'], bounding_box_format, 'xywh', image)\n","    return tf.data.Dataset.from_tensor_slices(boxes_in_xywh).map(get_piece)\n","\n","  def apply(dataset):\n","    return dataset.flat_map(get_pieces)\n","\n","  return apply"],"metadata":{"id":"UDvMbJvwbCvM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Line Detection 1"],"metadata":{"id":"ni8rKt4yYHXh"}},{"cell_type":"markdown","source":["This attempt at line detection came after the final model was developed and relies on some of the functions in `scorer.ipynb`. It was intended to replace the ORB matching portion of the final model."],"metadata":{"id":"-5IPuNtsaSAW"}},{"cell_type":"code","source":["image = cv.cvtColor(cv.imread(path.join(IMAGES_FOLDER, 'side_angle/IMG_6212.jpg')), cv.COLOR_BGR2RGB)\n","# image = cv.cvtColor(cv.imread(path.join(IMAGES_FOLDER, 'side_angle/IMG_4557.JPG')), cv.COLOR_BGR2RGB)\n","# image = cv.cvtColor(cv.imread(path.join(IMAGES_FOLDER, 'side_angle/IMG_0280.jpeg')), cv.COLOR_BGR2RGB)\n","\n","predictions = get_predictions(image)\n","_, board_preds = partition(lambda b: class_mapping[b[4]] == 'board', predictions)\n","board_pred = next(iter(sorted(board_preds, key=itemgetter(5), reverse=True)), None)\n","if board_pred is None:\n","  raise ValueError('Board could not be found')\n","board_pred = expand(board_pred, 1.25, image.shape[:2])\n","board_img, _ = extract(image, board_pred)\n","\n","_, thresh = cv.threshold(cv.cvtColor(board_img, cv.COLOR_RGB2GRAY), 0, 255, cv.THRESH_BINARY_INV+cv.THRESH_OTSU)\n","fig, ax = plt.subplots(1,1,figsize=(8,8))\n","ax.axis('off')\n","ax.imshow(thresh, cmap='gray')\n","plt.show()\n","\n","lines = [line[0] for line in cv.HoughLinesP(thresh,1,np.pi/180,100,minLineLength=500,maxLineGap=10)]\n","length = lambda line: sqrt((line[2]-line[0])**2+(line[3]-line[1])**2)\n","dist = lambda pt1, pt2: length([*pt1, *pt2])\n","slope = lambda line: (line[3]-line[1])/(line[2]-line[0])\n","slope_intercept = lambda line: (slope(line), line[1]-slope(line)*line[0])\n","dot = lambda line1, line2: (line1[2]-line1[0])*(line2[2]-line2[0])+(line1[3]-line1[1])*(line2[3]-line2[1])\n","def intersect(line1, line2):\n","  m,b = slope_intercept(line1)\n","  n,c = slope_intercept(line2)\n","  x = (b-c)/(n-m)\n","  y = m*x+b\n","  return round(x),round(y)\n","# https://www.math.utah.edu/~treiberg/Perspect/Perspect.htm\n","def fourth_point(o, ap, fp): # ap = a', fp = f'\n","  f = [o[0] + dist(o, fp), o[1]]\n","  x = (pt2[0]+pt3[0])/2\n","  y = (pt2[1]+pt3[1])/2\n","  return [round(x), round(y)]\n","\n","lines = sorted(lines, key=length, reverse=True)\n","longest = lines[0]\n","perp = min(lines, key=lambda line: dot(longest, line))\n","longest_perp = next(line for line in lines if abs(slope(perp) - slope(line)) < 0.5)\n","pt1 = intersect(longest, longest_perp)\n","dist_pt1 = lambda pt: dist(pt, pt1)\n","pt2 = max([longest[:2], longest[2:]], key=dist_pt1)\n","pt3 = max([longest_perp[:2], longest_perp[2:]], key=dist_pt1)\n","pt4 = fourth_point(pt1, pt2, pt3)\n","\n","h,w = board_ref_img.shape[:2]\n","src_pts = np.float32([[0,0], [0,h-1], [w-1,0], [w-1,h-1]]).reshape(-1,1,2)\n","dst_pts = np.float32([pt1, pt2, pt3, pt4]).reshape(-1,1,2)\n","homography, _ = cv.findHomography(src_pts, dst_pts, cv.RANSAC, 5.0)\n","\n","canvas = board_img.copy()\n","for line in [longest, longest_perp, [*pt2, *pt4], [*pt3, *pt4]]: # [[*pt1, *pt2], [*pt1, *pt3]]:\n","  x1,y1,x2,y2 = line\n","  cv.line(canvas,(x1,y1),(x2,y2),(128,255,255),20)\n","fig, ax = plt.subplots(1,1,figsize=(8,8))\n","ax.axis('off')\n","ax.imshow(canvas)\n","plt.show()\n","\n","# fig, ax = plt.subplots(1,1,figsize=(8,8))\n","# ax.axis('off')\n","# ax.imshow(cv.warpPerspective(board_img, homography, board_ref_img.shape[:2]))\n","# plt.show()"],"metadata":{"id":"T5NKKk_nYKsZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Line Detection 2"],"metadata":{"id":"HPCiMfGDckZk"}},{"cell_type":"markdown","source":["This attempt at line detection also came during development of the final model."],"metadata":{"id":"gy7EwvNPcqa-"}},{"cell_type":"code","source":["import math\n","def findAngle(line1, line2):\n","  (x11, y11, x21, y21) = line1\n","  vec1 = np.array([(y21 - y11) / (x21 - x11), 1])\n","  (x12, y12, x22, y22) = line2\n","  vec2 = np.array([(y22 - y12) / (x22 - x12), 1])\n","  x = vec1.dot(vec2) / math.sqrt(vec1.dot(vec1) * vec2.dot(vec2))\n","  angle = math.acos(x)*180 / np.pi \n","  return angle\n","\n","def find_piece_grid(board_img, piece_preds):\n","  centers = [center(p) for p in piece_preds]\n","  max_dist = board_img.shape[0] // 5\n","  min_dist = round(max_dist * math.sqrt(2) / 2)\n","  remove_idxs = []\n","  for i in range(len(centers)):\n","    for j in range(i):\n","      x1, y1 = centers[i]\n","      x2, y2 = centers[j]\n","      distance = math.sqrt(((x2 - x1) ** 2) + ((y2 - y1) ** 2))\n","      if distance < min_dist:\n","        c1 = piece_preds[i][5]\n","        c2 = piece_preds[j][5]\n","        remove_idxs.append(i if c1 < c2 else j)\n","  remove_idxs = [*set(remove_idxs)] # get rid of dupes\n","  print(len(centers))\n","  clean_centers = []\n","  for i in range(len(centers)):\n","    if i in remove_idxs:\n","      continue\n","    clean_centers.append(centers[i])\n","  print(len(clean_centers))\n","  lines = []\n","  for i in range(len(clean_centers)):\n","    for j in range(i):\n","      lines.append((clean_centers[i][0], clean_centers[i][1], clean_centers[j][0], clean_centers[j][1]))\n","\n","  print(lines)\n","  \n","  # print(max_dist, min_dist)\n","  grid = [[(None, 0) for _ in range(4)] for _ in range(4)]\n","  return grid"],"metadata":{"id":"CeZ5vOENckoW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Line Detection 3"],"metadata":{"id":"cPXw-kd4xt9g"}},{"cell_type":"code","source":["import time\n","img = cv.imread('/content/drive/Shareddrives/DCC Capstone/Images/board_side_1.png')\n","gray = cv.cvtColor(img,cv.COLOR_BGR2GRAY)\n","imshow(gray)\n","alpha = 1.5\n","beta = 50\n","adjusted_gray = cv.convertScaleAbs(gray, alpha=alpha, beta=beta)\n","imshow(adjusted_gray)\n","inv_gray = cv.bitwise_not(adjusted_gray)\n","imshow(inv_gray)\n","kernel_size = 5\n","blur_gray = cv.GaussianBlur(inv_gray,(kernel_size, kernel_size),0)\n","imshow(blur_gray)\n","# for i in range(1, 21):\n","#   for j in range(i - 1):\n","#     low_threshold = j * 10\n","#     high_threshold = i * 10\n","#     edges = cv.Canny(blur_gray, low_threshold, high_threshold)\n","#     imshow(edges)\n","#     time.sleep(.2)\n","low_threshold = 20\n","high_threshold = 100\n","edges = cv.Canny(blur_gray, low_threshold, high_threshold)\n","imshow(edges)\n","\n","\n","\n","rho = 1  # distance resolution in pixels of the Hough grid\n","theta = np.pi / 180  # angular resolution in radians of the Hough grid\n","threshold = 30  # minimum number of votes (intersections in Hough grid cell)\n","min_line_length = 250  # minimum number of pixels making up a line\n","max_line_gap = 50  # maximum gap in pixels between connectable line segments\n","line_image = np.copy(img) * 0  # creating a blank to draw lines on\n","\n","# Run Hough on edge detected image\n","# Output \"lines\" is an array containing endpoints of detected line segments\n","lines = cv.HoughLinesP(edges, rho, theta, threshold, np.array([]),\n","                    min_line_length, max_line_gap)\n","\n","for line in lines:\n","  for x1,y1,x2,y2 in line:\n","    # print(line)\n","    cv.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n","\n","# # Draw the lines on the  image\n","lines_edges = cv.addWeighted(img, 0.8, line_image, 1, 0)\n","lines_edges\n","imshow(line_image)"],"metadata":{"id":"YzvVPOAcxvYz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import math\n","# def isPerpendicular(line1, line2, factor):\n","#   (x11, y11, x21, y21) = line1\n","#   vec1 = np.array([(y21 - y11) / (x21 - x11), 1])\n","#   (x12, y12, x22, y22) = line2\n","#   vec2 = np.array([(y22 - y12) / (x22 - x12), 1])\n","#   x = vec1.dot(vec2) / math.sqrt(vec1.dot(vec1) * vec2.dot(vec2))\n","#   angle = math.acos(x) *180 / np.pi\n","#   if angle < 90 + factor and angle > 90 - factor:\n","#     return True\n","#   return False\n","# def isParallel(line1, line2, factor):\n","#   (x11, y11, x21, y21) = line1\n","#   vec1 = np.array([(y21 - y11) / (x21 - x11), 1])\n","#   (x12, y12, x22, y22) = line2\n","#   vec2 = np.array([(y22 - y12) / (x22 - x12), 1])\n","#   x = vec1.dot(vec2) / math.sqrt(vec1.dot(vec1) * vec2.dot(vec2))\n","#   angle = math.acos(x)*180 / np.pi \n","#   print(angle)\n","#   print(factor)\n","#   if angle < factor:\n","#     True\n","#   return False\n","\n","def findAngle(line1, line2):\n","  (x11, y11, x21, y21) = line1\n","  vec1 = np.array([(y21 - y11) / (x21 - x11), 1])\n","  (x12, y12, x22, y22) = line2\n","  vec2 = np.array([(y22 - y12) / (x22 - x12), 1])\n","  x = vec1.dot(vec2) / math.sqrt(vec1.dot(vec1) * vec2.dot(vec2))\n","  angle = math.acos(x)*180 / np.pi \n","  return angle\n","\n","def is_arr_in_list(myarr, list_arrays):\n","  return next((True for elem in list_arrays if elem is myarr), False)"],"metadata":{"id":"ViSLMsiwcJy6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["perpendicular_factor = 10\n","vertical_factor = 0.1\n","parallel_factor = 12\n","\n","perpendicular_lines = []\n","for i in range(len(lines)):\n","  perpendicular_lines.append(0)\n","  for j in range(i + 1, len(lines)):\n","    angle = findAngle(lines[i][0], lines[j][0])\n","    if angle > 90 - perpendicular_factor and angle < 90 + perpendicular_factor:\n","      perpendicular_lines[i] += 1\n"],"metadata":{"id":"c66WZhnkcLVu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(perpendicular_lines)"],"metadata":{"id":"uD9j13s6cMcd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["best_line = lines[perpendicular_lines.index(max(perpendicular_lines))][0]\n","print(best_line)\n","parallels = []\n","perpendiculars = []\n","for line in lines:\n","  angle = findAngle(best_line, line[0])\n","  if angle < parallel_factor:\n","    parallels.append(line)\n","  elif angle > 90 - perpendicular_factor and angle < 90 + perpendicular_factor:\n","    perpendiculars.append(line)"],"metadata":{"id":"JiBsjy8OcNht"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["par_slopes = 0\n","\n","for line in parallels:\n","  (x1, y1, x2, y2) = line[0]\n","  par_slopes += (y2 - y1) / (x2 - x1)\n","\n","par_slopes_avg = par_slopes / len(parallels)\n","par_T = np.linalg.inv(np.array([[1, par_slopes_avg], [par_slopes_avg, -1]]))\n","\n","perp_slopes = 0\n","for line in perpendiculars:\n","  (x1, y1, x2, y2) = line[0]\n","  perp_slopes += (y2 - y1) / (x2 - x1)\n","\n","perp_slopes_avg = perp_slopes / len(perpendiculars)\n","perp_T = np.linalg.inv(np.array([[1, perp_slopes_avg], [perp_slopes_avg, -1]]))\n","\n","par_x_values = []\n","par_y_values = []\n","for line in parallels:\n","  (x1, y1, x2, y2) = line[0]\n","  mid = np.array([(x2 + x1) / 2, (y2 + y1) / 2])\n","  par_x_values.append(par_T.dot(mid)[0])\n","  par_y_values.append(par_T.dot(mid)[1])\n","\n","perp_x_values = []\n","perp_y_values = []\n","for line in perpendiculars:\n","  (x1, y1, x2, y2) = line[0]\n","  mid = np.array([(x2 + x1) / 2, (y2 + y1) / 2])\n","  perp_x_values.append(perp_T.dot(mid)[0])\n","  perp_y_values.append(perp_T.dot(mid)[1])"],"metadata":{"id":"M1FNYKM5cPFw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(par_slopes_avg)"],"metadata":{"id":"uk1VeQvWcQSj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install ckwrap"],"metadata":{"id":"ugi3bUgzcSlc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import ckwrap\n","import sys\n","k = 12\n","par_km = ckwrap.ckmeans(par_y_values, k)\n","perp_km = ckwrap.ckmeans(perp_y_values, k)\n","\n","par_labels = par_km.labels\n","perp_labels = perp_km.labels\n","\n","# print(par_km.centers)\n","par_min_err = float(\"inf\")\n","par_min_err_clusters = []\n","par_delta = 0\n","perp_min_err = float(\"inf\")\n","perp_min_err_clusters = []\n","perp_delta = 0\n","for i1 in range(4, k):\n","  for i2 in range(3, i1):\n","    for i3 in range(2, i2):\n","      for i4 in range(1, i3):\n","        for i5 in range(i4):\n","          par_centers = [par_km.centers[i1], par_km.centers[i2], par_km.centers[i3], par_km.centers[i4], par_km.centers[i5]]\n","          par_centers.sort()\n","          par_diffs = [par_centers[1] - par_centers[0], par_centers[2] - par_centers[1], par_centers[3] - par_centers[2], par_centers[4] - par_centers[3]]\n","          par_errs = []\n","          for i in range(len(par_diffs)):\n","            for j in range(i + 1, len(par_diffs)):\n","              par_errs.append(abs(par_diffs[i] - par_diffs[j]))\n","          par_err = sum(par_errs) / len(par_errs)\n","          # print(err)\n","          if par_err < par_min_err:\n","            par_delta = sum(par_diffs) / len(par_diffs)\n","            par_min_err = par_err\n","            par_min_err_clusters = [i1, i2, i3, i4, i5]\n","\n","          perp_centers = [perp_km.centers[i1], perp_km.centers[i2], perp_km.centers[i3], perp_km.centers[i4], perp_km.centers[i5]]\n","          perp_centers.sort()\n","          perp_diffs = [perp_centers[1] - perp_centers[0], perp_centers[2] - perp_centers[1], perp_centers[3] - perp_centers[2], perp_centers[4] - perp_centers[3]]\n","          perp_errs = []\n","          for i in range(len(perp_diffs)):\n","            for j in range(i + 1, len(perp_diffs)):\n","              perp_errs.append(abs(perp_diffs[i] - perp_diffs[j]))\n","          perp_err = sum(perp_errs) / len(perp_errs)\n","          # print(err)\n","          if perp_err < perp_min_err:\n","            perp_delta = sum(perp_diffs) / len(perp_diffs)\n","            perp_min_err = perp_err\n","            perp_min_err_clusters = [i1, i2, i3, i4, i5]\n"],"metadata":{"id":"RKHEV83ocS2O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(par_min_err_clusters)\n","for i in range(5):\n","  print(par_km.centers[par_min_err_clusters[i]])\n","print(par_delta)"],"metadata":{"id":"9vDbvy4ucUkb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from matplotlib import pyplot as pltimport\n"," \n"," \n","# Creating dataset\n"," \n","# Creating histogram\n","fig, ax = plt.subplots(figsize =(10, 7))\n","# ax.plot(perp_x_values, perp_y_values, 'bo')\n","ax.plot(par_x_values, par_y_values, 'ro')\n","# ax.hist(par_x_values, bins = 30)\n","# ax.hist(perp_y_values, bins = 30)\n","# ax.hist(par_y_values, bins = 30)\n","\n","# Show plot\n","plt.show()"],"metadata":{"id":"alryqLiIcVuI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["curr_lab = 9\n","line_image_2 = np.copy(img) * 0  # creating a blank to draw lines on\n","# for i in range(len(parallels)):\n","#   line = parallels[i]\n","#   for x1,y1,x2,y2 in line:\n","#     # print(line)\n","#     label = par_labels[i]\n","#     if label != curr_lab:\n","#       continue\n","#     # if label not in par_min_err_clusters:\n","#     #   continue\n","#     pt1 = par_T.dot(np.array([x1,y1]))\n","#     pt1t = (round(pt1[0])+ 1200, round(pt1[1]) + 1600)\n","#     pt2 = par_T.dot(np.array([x2,y2]))\n","#     pt2t = (round(pt2[0])+ 1200, round(pt2[1])+ 1600)\n","#     # print(pt1, pt2)\n","#     cv.line(line_image_2,pt1t,pt2t,(255,0,0),5)\n","#     cv.line(line_image_2, [x1, y1], [x2, y2],(255,0,0),5)\n","# for i in range(len(perpendiculars)):\n","#   line = perpendiculars[i]\n","#   for x1,y1,x2,y2 in line:\n","#     # print(line)\n","#     label = perp_labels[i]\n","#     # if label != curr_lab:\n","#     #   continue\n","#     if label not in perp_min_err_clusters:\n","#       continue\n","#     pt1 = perp_T.dot(np.array([x1,y1]))\n","#     pt1t = (round(pt1[0]) + 500, round(pt1[1]) + 1200)\n","#     pt2 = perp_T.dot(np.array([x2,y2]))\n","#     pt2t = (round(pt2[0]) + 500, round(pt2[1]) + 1200)\n","#     # print(pt1, pt2)\n","#     cv.line(line_image_2,pt1t,pt2t,(0,255,0),5)\n","#     cv.line(line_image_2, [x1, y1], [x2, y2],(255,0,0),5)\n","# for i in range(len(parallels)):\n","#   line = parallels[i]\n","#   for x1,y1,x2,y2 in line:\n","#     # print(line)\n","#     label = par_labels[i]\n","#     # if label != curr_lab:\n","#     #   continue\n","#     # if label not in par_min_err_clusters:\n","#     #   continue\n","#     cv.line(line_image_2,(x1,y1),(x2,y2),(255,0,0),5)\n","\n","# for i in range(len(perpendiculars)):\n","#   line = perpendiculars[i]\n","#   for x1,y1,x2,y2 in line:\n","#     # print(line)\n","#     label = perp_labels[i]\n","#     # if label != curr_lab:\n","#     #   continue\n","#     # if label in perp_min_err_clusters:\n","#     #   continue\n","#     cv.line(line_image_2,(x1,y1),(x2,y2),(0,255,0),5)\n","\n","for (x1, y1, x2, y2) in lines[perpendicular_lines.index(max(perpendicular_lines))]:\n","  cv.line(line_image_2, (x1,y1),(x2,y2),(0,255,0),5)\n","# # Draw the lines on the  image\n","# lines_edges_2 = cv.addWeighted(img, 0.8, line_image, 1, 0)\n","# lines_edges_2\n","imshow(line_image_2)"],"metadata":{"id":"5Pmfa_PxcYF4"},"execution_count":null,"outputs":[]}]}